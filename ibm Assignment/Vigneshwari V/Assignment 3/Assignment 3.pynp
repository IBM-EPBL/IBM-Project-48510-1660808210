{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Dataset\n"
      ],
      "metadata": {
        "id": "P5YOizw-dT9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiy1CpnidQ9J",
        "outputId": "ccacea1a-3f2d-4ff8-8dc2-bac759de6a36"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1ROB4BNR_QL"
      },
      "source": [
        "#Image Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VXIBx4voSD_B"
      },
      "outputs": [],
      "source": [
        "# Importing Library\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LSgOZPtLSX9p"
      },
      "outputs": [],
      "source": [
        "# expanding training and testing variable\n",
        "train_d=ImageDataGenerator(rescale=1./255,zoom_range=0.2,horizontal_flip=True)\n",
        "test_d=ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qld6q72-SszV",
        "outputId": "01065c5b-3b40-4def-a955-97f853033334"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4334 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "#Data augmentation on testing data\n",
        "vtrain = train_d.flow_from_directory('/content/drive/MyDrive/flowers/Testing',target_size=(76,76),class_mode='categorical',batch_size=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRGjcgGdT5Q7",
        "outputId": "b78bce6d-7120-4208-c0c4-2302de9184f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4372 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "#Data augmentation on training data\n",
        "vtest = test_d.flow_from_directory('/content/drive/MyDrive/flowers/Training',target_size=(76,76),class_mode='categorical',batch_size=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh5LMq-uYVR7"
      },
      "source": [
        "#Creating CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tnIn5ph6Ybhq"
      },
      "outputs": [],
      "source": [
        "#Importing Libraries\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HjIEUYwIZBB-"
      },
      "outputs": [],
      "source": [
        "#Building a CNN block\n",
        "model = Sequential()\n",
        "model.add(Convolution2D(32,(3,3),activation='relu',input_shape=(76,76,3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500,activation='relu'))\n",
        "model.add(Dense(250,activation='relu'))\n",
        "model.add(Dense(5,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZdxpLb7ba8zH"
      },
      "outputs": [],
      "source": [
        "#Compiling the model\n",
        "\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8YYDH4JNHUd",
        "outputId": "0cb6a330-3553-4510-eb8d-2e50878b09fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "22/22 [==============================] - 1419s 66s/step - loss: 2.4632 - accuracy: 0.2995 - val_loss: 1.2851 - val_accuracy: 0.4376\n",
            "Epoch 2/15\n",
            "22/22 [==============================] - 64s 3s/step - loss: 1.2076 - accuracy: 0.5074 - val_loss: 1.1575 - val_accuracy: 0.5320\n",
            "Epoch 3/15\n",
            "22/22 [==============================] - 62s 3s/step - loss: 1.0800 - accuracy: 0.5743 - val_loss: 1.0376 - val_accuracy: 0.5958\n",
            "Epoch 4/15\n",
            "22/22 [==============================] - 63s 3s/step - loss: 0.9855 - accuracy: 0.6214 - val_loss: 0.9492 - val_accuracy: 0.6414\n",
            "Epoch 5/15\n",
            "22/22 [==============================] - 63s 3s/step - loss: 0.8937 - accuracy: 0.6622 - val_loss: 0.9133 - val_accuracy: 0.6530\n",
            "Epoch 6/15\n",
            "22/22 [==============================] - 63s 3s/step - loss: 0.8337 - accuracy: 0.6751 - val_loss: 0.7866 - val_accuracy: 0.7091\n",
            "Epoch 7/15\n",
            "22/22 [==============================] - 63s 3s/step - loss: 0.7875 - accuracy: 0.7037 - val_loss: 0.7907 - val_accuracy: 0.7100\n",
            "Epoch 8/15\n",
            "22/22 [==============================] - 65s 3s/step - loss: 0.7410 - accuracy: 0.7220 - val_loss: 0.6903 - val_accuracy: 0.7434\n",
            "Epoch 9/15\n",
            "22/22 [==============================] - 65s 3s/step - loss: 0.7011 - accuracy: 0.7323 - val_loss: 0.6207 - val_accuracy: 0.7699\n",
            "Epoch 10/15\n",
            "22/22 [==============================] - 66s 3s/step - loss: 0.6562 - accuracy: 0.7575 - val_loss: 0.6067 - val_accuracy: 0.7793\n",
            "Epoch 11/15\n",
            "22/22 [==============================] - 63s 3s/step - loss: 0.6345 - accuracy: 0.7637 - val_loss: 0.7020 - val_accuracy: 0.7381\n",
            "Epoch 12/15\n",
            "22/22 [==============================] - 63s 3s/step - loss: 0.6324 - accuracy: 0.7649 - val_loss: 0.5490 - val_accuracy: 0.8008\n",
            "Epoch 13/15\n",
            "22/22 [==============================] - 63s 3s/step - loss: 0.6061 - accuracy: 0.7695 - val_loss: 0.5225 - val_accuracy: 0.8118\n",
            "Epoch 14/15\n",
            "22/22 [==============================] - 65s 3s/step - loss: 0.5382 - accuracy: 0.8032 - val_loss: 0.4787 - val_accuracy: 0.8255\n",
            "Epoch 15/15\n",
            "22/22 [==============================] - 66s 3s/step - loss: 0.5271 - accuracy: 0.8050 - val_loss: 0.5410 - val_accuracy: 0.8001\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9e94a95e90>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#Fittting the model\n",
        "\n",
        "model.fit_generator(vtrain,steps_per_epoch=len(vtrain),epochs=15,validation_data=vtest,validation_steps=len(vtest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Nf-WIr1yYrkT"
      },
      "outputs": [],
      "source": [
        "# save model\n",
        "model.save('flowers.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kps61o3ogloY"
      },
      "source": [
        "# Testing model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7vXzTadi5ioP"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MQLllcr4gvdt",
        "outputId": "520f24c4-baa2-43a5-b6a2-f309ccb5e0a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'daisy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Testing 1.1(daisy)\n",
        "\n",
        "img = image.load_img('/content/drive/MyDrive/flowers/Testing/daisy/10993818044_4c19b86c82.jpg',target_size=(76,76))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x,axis=0)\n",
        "prediction = np.argmax(model.predict(x))\n",
        "op = ['daisy','dandelion','rose','sunflower','tulip']\n",
        "op[prediction]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing 1.2(daisy)\n",
        "\n",
        "img = image.load_img('/content/drive/MyDrive/flowers/Testing/daisy/525780443_bba812c26a_m.jpg',target_size=(76,76))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x,axis=0)\n",
        "prediction = np.argmax(model.predict(x))\n",
        "op = ['daisy','dandelion','rose','sunflower','tulip']\n",
        "op[prediction]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "esjPurgq4KtM",
        "outputId": "24ec8e81-eaba-4e3b-fe11-9d01548d460a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'daisy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing 2.1(dandelion)\n",
        "\n",
        "img = image.load_img('/content/drive/MyDrive/flowers/Testing/dandelion/1195255751_d58b3d3076.jpg',target_size=(76,76))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x,axis=0)\n",
        "prediction = np.argmax(model.predict(x))\n",
        "op = ['daisy','dandelion','rose','sunflower','tulip']\n",
        "op[prediction]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pODnKlUFubwt",
        "outputId": "a2f851d2-1ec5-495f-8fe1-68dc0cd13435"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sunflower'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing 2.2(dandelion)\n",
        "\n",
        "img = image.load_img('/content/drive/MyDrive/flowers/Testing/dandelion/1297972485_33266a18d9.jpg',target_size=(76,76))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x,axis=0)\n",
        "prediction = np.argmax(model.predict(x))\n",
        "op = ['daisy','dandelion','rose','sunflower','tulip']\n",
        "op[prediction]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Q4vExyy-4g_w",
        "outputId": "194c47a2-abc4-480c-a6fd-0830e65a49f8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'daisy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing 3.1(rose)\n",
        "\n",
        "img = image.load_img('/content/drive/MyDrive/flowers/Testing/rose/7456887736_54e4ebac03_n.jpg',target_size=(76,76))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x,axis=0)\n",
        "prediction = np.argmax(model.predict(x))\n",
        "op = ['daisy','dandelion','rose','sunflower','tulip']\n",
        "op[prediction]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "K3dk8vORx3mx",
        "outputId": "c3eccf28-8732-4bd2-ef38-7898d664a3dc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rose'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing 3.2(rose)\n",
        "\n",
        "img = image.load_img('/content/drive/MyDrive/flowers/Testing/rose/33411423082_8150d9254e_n.jpg',target_size=(76,76))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x,axis=0)\n",
        "prediction = np.argmax(model.predict(x))\n",
        "op = ['daisy','dandelion','rose','sunflower','tulip']\n",
        "op[prediction]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "s8g3sRY35G76",
        "outputId": "c38b3e33-2f22-4e56-d53a-5947072009bb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rose'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing 4.1(sunflower)\n",
        "\n",
        "img = image.load_img('/content/drive/MyDrive/flowers/Testing/sunflower/7012364067_5ffc7654c9_m.jpg',target_size=(76,76))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x,axis=0)\n",
        "prediction = np.argmax(model.predict(x))\n",
        "op = ['daisy','dandelion','rose','sunflower','tulip']\n",
        "op[prediction]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "48WPc6OczA6K",
        "outputId": "25699cc9-286b-4737-f1fe-877d6046b616"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sunflower'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing 4.2(sunflower)\n",
        "\n",
        "img = image.load_img('/content/drive/MyDrive/flowers/Testing/sunflower/2720698862_486d3ec079_m.jpg',target_size=(76,76))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x,axis=0)\n",
        "prediction = np.argmax(model.predict(x))\n",
        "op = ['daisy','dandelion','rose','sunflower','tulip']\n",
        "op[prediction]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vOxFEEJd5T3P",
        "outputId": "6a0da65b-9ae5-41e5-e79d-8969b9076712"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sunflower'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing 5.1(tulip)\n",
        "\n",
        "img = image.load_img('/content/drive/MyDrive/flowers/Testing/tulip/8892851067_79242a7362_n.jpg',target_size=(76,76))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x,axis=0)\n",
        "prediction = np.argmax(model.predict(x))\n",
        "op = ['daisy','dandelion','rose','sunflower','tulip']\n",
        "op[prediction]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VF4Wx20J0YX5",
        "outputId": "f641d00f-8659-4f14-daff-03532de1fdb9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tulip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing 5.2(tulip)\n",
        "\n",
        "img = image.load_img('/content/drive/MyDrive/flowers/Testing/tulip/5546723510_39a5a10d3a_n.jpg',target_size=(76,76))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x,axis=0)\n",
        "prediction = np.argmax(model.predict(x))\n",
        "op = ['daisy','dandelion','rose','sunflower','tulip']\n",
        "op[prediction]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mYTzhVCe5bs1",
        "outputId": "a6b0f6af-0791-4023-f61e-802d36b43a02"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tulip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
